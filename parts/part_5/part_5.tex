\part{Production Deployment}

\chapter{Model Optimization}
\section{Model Compression}
\subsection{Quantization}
\subsection{Pruning}
\subsection{Knowledge Distillation}
\subsection{Neural Architecture Search}
\section{Model Acceleration}
\subsection{TensorRT}
\subsection{ONNX Runtime}
\subsection{OpenVINO}
\subsection{TensorFlow Lite}
\section{Model Deployment}
\subsection{TensorFlow Serving}
\subsection{TorchServe}
\subsection{NVIDIA Triton Inference Server}
\subsection{MLflow}
\subsection{Kubeflow}
\section{Model Monitoring}
\subsection{Prometheus}
\subsection{Grafana}
\subsection{Seldon}
\subsection{Evidently}
\section{Model Versioning}
\subsection{DVC}
\subsection{MLflow}
\subsection{Weights \& Biases}